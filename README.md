# Vortex E-Commerce: Order Service

`order-service` es un microservicio backend para gestionar pedidos dentro de la plataforma de e-commerce de alto tr√°fico Vortex. Est√° dise√±ado para ser resiliente, escalable y mantenible, utilizando un enfoque de arquitectura hexagonal y comunicaci√≥n basada en eventos.

## ‚ú® Caracter√≠sticas

- **Creaci√≥n y gesti√≥n de √≥rdenes**: Soporte para el ciclo de vida completo de una orden (creaci√≥n, procesamiento, env√≠o, entrega, cancelaci√≥n).
- **Arquitectura Hexagonal**: Separaci√≥n clara entre la l√≥gica de negocio (dominio), los casos de uso (aplicaci√≥n) y la tecnolog√≠a (infraestructura).
- **Comunicaci√≥n As√≠ncrona**: Utiliza Apache Kafka para publicar eventos de √≥rdenes, permitiendo que otros servicios (como notificaciones o inventario) reaccionen a los cambios de estado de forma desacoplada.
- **Seguridad**: Protegido con Spring Security y autenticaci√≥n basada en tokens JWT.
- **Cach√© Distribuido**: Integraci√≥n con Redis para cachear datos y mejorar el rendimiento.
- **Manejo de Concurrencia**: Implementa bloqueo optimista para prevenir conflictos en actualizaciones de datos.

## üèóÔ∏è Estructura del Proyecto

El proyecto sigue los principios de la **Arquitectura Hexagonal** (tambi√©n conocida como Puertos y Adaptadores) para aislar la l√≥gica de negocio central de las dependencias externas.

- `domain`: El n√∫cleo del servicio. Contiene los modelos de negocio (`Order`, `OrderItem`), las reglas de negocio, las excepciones personalizadas y los *puertos* (interfaces que definen contratos para la comunicaci√≥n con el exterior, como `OrderRepositoryPort` o `InventoryPort`). No tiene dependencias de ning√∫n framework.
- `application`: La capa de orquestaci√≥n. Contiene los casos de uso o servicios (`OrderService`) que utilizan el dominio para ejecutar las acciones solicitadas por el usuario.
- `infrastructure`: Contiene las implementaciones concretas (adaptadores) de los puertos definidos en el dominio.
  - `adapter/in`: Puntos de entrada a la aplicaci√≥n.
    - `web`: Controladores REST que exponen la API.
    - `kafka`: Consumidores de eventos de Kafka.
  - `adapter/out`: Puntos de salida de la aplicaci√≥n.
    - `persistence`: Implementaci√≥n de los repositorios utilizando Spring Data JPA.
    - `kafka`: Productores de eventos para Kafka.
    - `http`: Clientes para consumir otras APIs (ej. servicio de inventario).
  - `config`: Clases de configuraci√≥n de Spring para beans, seguridad, cach√©, etc.
  - `security`: Implementaci√≥n de la l√≥gica de JWT.

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Lenguaje**: Java 21
- **Framework**: Spring Boot 3.3.1
- **Datos**:
  - Spring Data JPA / Hibernate
  - Base de datos en memoria H2 (para desarrollo y pruebas)
- **Mensajer√≠a**:
  - Spring for Apache Kafka (para arquitectura orientada a eventos)
- **Cach√©**:
  - Spring Cache
  - Redis
- **Seguridad**:
  - Spring Security
  - JSON Web Tokens (JWT)
- **Build y Dependencias**:
  - Apache Maven
  - Lombok (para reducir c√≥digo boilerplate)
  - MapStruct (para mapeo de objetos)
- **Pruebas**:
  - JUnit 5, Mockito, AssertJ
  - Spring Boot Test, Spring Security Test
  - Testcontainers (para pruebas de integraci√≥n con Kafka y Redis)
- **Calidad de C√≥digo**:
  - Jacoco (para reportes de cobertura de c√≥digo)

## üöÄ Ejecuci√≥n y Despliegue

### Prerrequisitos

- JDK 21 o superior.
- Apache Maven 3.8 o superior.
- Docker y Docker Compose (para levantar los servicios de infraestructura).

### 1. Ejecuci√≥n Local

Para ejecutar la aplicaci√≥n en un entorno local, es necesario levantar las dependencias de infraestructura (Kafka y Redis). Se proporciona un archivo `docker-compose.yml` para facilitar este proceso.

**a. Levantar la infraestructura con Docker:**

Desde la ra√≠z del proyecto, ejecuta:
```bash
docker-compose up -d
```
Este comando iniciar√° contenedores para:
- Zookeeper (en el puerto `2181`)
- Kafka (en el puerto `9092`)
- Redis (en el puerto `6379`)

**b. Configurar la aplicaci√≥n:**

El archivo `application.properties` est√° configurado para conectarse a servicios en la nube. Para el desarrollo local, es recomendable usar un perfil de Spring.

Crea un archivo `src/main/resources/application-local.properties` con el siguiente contenido para apuntar a los servicios de Docker:

```properties
# Kafka
spring.kafka.bootstrap-servers=localhost:9092
app.kafka.topic.replicas=1 # En local, solo tenemos un broker

# Redis
spring.data.redis.host=localhost
spring.data.redis.port=6379
spring.data.redis.password=
spring.data.redis.ssl.enabled=false
```

**c. Iniciar la aplicaci√≥n:**

Puedes iniciar la aplicaci√≥n desde tu IDE o usando el siguiente comando de Maven, activando el perfil `local`:

```bash
mvn spring-boot:run -Dspring-boot.run.profiles=local
```

La aplicaci√≥n estar√° disponible en `http://localhost:8080`.

### 2. Ejecutar Pruebas

Para ejecutar el conjunto completo de pruebas unitarias y de integraci√≥n, utiliza el siguiente comando de Maven. Esto tambi√©n generar√° un reporte de cobertura en `target/site/jacoco/index.html`.

```bash
mvn clean verify
```

## üîë API y Autenticaci√≥n

La API est√° protegida y requiere un token JWT para la mayor√≠a de los endpoints.

### 1. Obtener un Token

Puedes obtener un token autentic√°ndote con uno de los usuarios de prueba definidos en `application.properties`.

**Request:**
```bash
curl -X POST http://localhost:8080/api/auth/login \
-H "Content-Type: application/json" \
-d '{
    "username": "user",
    "password": "user123"
}'
```

### Consola H2

Mientras la aplicaci√≥n se ejecuta con el perfil por defecto o `local`, puedes acceder a la consola de la base de datos en memoria H2 para inspeccionar los datos.

- **URL**: `http://localhost:8080/h2-console`
- **JDBC URL**: `jdbc:h2:mem:vortexdb`
- **Username**: `vortex`
- **Password**: `admin1234`

## ‚òÅÔ∏è Despliegue en Azure

El archivo `azure-deploy.yml` contiene una definici√≥n de plantilla de Azure Resource Manager (ARM) para desplegar los contenedores de Kafka y Zookeeper en Azure Container Instances (ACI). Esto sirve como ejemplo de c√≥mo se podr√≠a configurar un entorno de desarrollo/pruebas en la nube.
